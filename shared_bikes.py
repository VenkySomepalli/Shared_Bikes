# -*- coding: utf-8 -*-
"""Shared_Bikes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QeLbNY7pR-5ocWnrp8siiX4s8LVDOZmR

**Business goal**

We need a model to predict the shared bikes demand with the available independent variables (features). It will be used by the company or management to understand how exactly the demands vary with different features. They can accordingly manipulate the business strategy to meet the demand levels and reach the customer's expectations.

#**Load the Shared Bike data set**
"""

from google.colab import files
upload = files.upload()

import pandas as pd 
bike = pd.read_csv("day.csv")

bike.head()

"""**Understaning data**"""

bike.columns

bike.shape

bike.info()

bike.describe()

"""**Useful insights from data:**

*   Data have 730 rows and 16 columns.

*  Except One column all are either integer or float


***From data dictionary we understood that:***

1.  *instant* column is a just index numbers, couldn't get the any information from this column. So, we can be removed *instant* column.
2.   *dteday* is date column, but in the data have month and year  separate columns. We can drop *dteday* column it not bringing any new information.
3. In addition of casual and registered columns contains the count of bike booked by different categories of customers, and we will not going to get much information from these columns, thus we wil drop these two as well.

**TARGET variable/column is 'cnt'**

#**Data visualization**
"""

# Drop columns
bike.drop(["instant", "dteday", "casual", "registered"], axis = 1, inplace = True)

bike.columns

# For better undestanding and visibility of few columns[Renamed]
bike.rename(columns={'season':'Season','yr':'Year','mnth':'Month',
                     'weathersit':'Weather','hum':'Humidity','cnt':'Count'}, inplace=True)

bike.head()

"""Above, all the columns shows numerical type, but from the data dictionary we see that there are some columns which represents categorical data.

**Binary Types :** Year, holiday, workingday

**Categorical Types:** Season, Month, weekday, Weather

**Numeric types:** temp, atemp, Humidity, windspeed, Count
"""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
# Mapping weather names for better visibilty
# Season (1:spring, 2:summer, 3:fall, 4:winter)
bike['Season'] = bike['Season'].map({1:'spring',2:'summer',3:'fall',4:'winter'})

bike.head()

# Visualising Seasons count of rented bikes

plt.figure(figsize=[10,4])
sns.barplot(bike['Season'],bike['Count'])
plt.title('Seasons Average Count', fontsize = 20)
plt.show()

"""**Observations:**

*   In fall, there seems to be highest demand of rented the bikes, followed by Summer and Winter.
*   Spring seems to be the least season where people rent bikes. 
"""

# Mapping Year varible proper names for better visibilty

bike['Year'] = bike['Year'].map({0:'2018',1:'2019'})
bike.head()

# Visualising Yearly count of rented bikes

sns.barplot(bike['Year'],bike['Count'])
plt.title('Yearly Average Count', fontsize = 20)
plt.show()

"""Average rented bikes has increased in 2019 nearly 40% more than that of 2018."""

# Mapping Month varible proper names for better visibilty

bike['Month'] = bike['Month'].map({1:'Jan',2:'Feb',3:'Mar',4:'April',
                                       5:'May',6:'June',7:'July',8:'Aug',
                                       9:'Sept',10:'Oct',11:'Nov',12:'Dec'})
bike.head()

# Visualising Monthly count of rented bikes

plt.figure(figsize=[14,5])
sns.barplot(bike['Month'],bike['Count'])
plt.title('Monthly Average Count', fontsize = 20)
plt.show()

"""Almost similar average count of rented bikes in June, September,  August, July followed by May, October.

Finally, December, January, February have the least demand probably due to winter season.
"""

# Mapping weekday variable proper names for better visibilty

bike['weekday'] = bike['weekday'].map({0:'Mon',1:'Tues',2:'Wed',3:'Thurs',4:'Fri',5:'Sat',6:'Sun'})

# Visualising Daily count of rented bikes

plt.figure(figsize=[14,5])
sns.barplot(bike['weekday'],bike['Count'])
plt.title('Average Daily Count', fontsize = 20)
plt.show()

"""It looks like all days have similar demands, but still Friday, Saturday Sunday, Monday has high demands compare to other days."""

# Mapping workingday varible proper names for better visibilty

bike['workingday'] = bike['workingday'].map({0:'No',1:'Yes'})

# Visualising Working day count of rented bikes

sns.barplot(bike['workingday'],bike['Count'])

plt.title('Working Day Average Count', fontsize = 20)
plt.show()

"""Similar demands either working or not working days."""

# Mapping Weather varible proper names for better visibilty

# Weather situation : 
# 1: Clear, Few clouds, Partly cloudy   = Good/Clear
# 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist = Moderate/Mist
# 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds  = Bad/Light Rain
# 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog = Worse/Heavy Rain


bike['Weather'] = bike['Weather'].map({1:"Good/Clear",2:'Moderate/Misty',3:'Bad/LightRain',4:'Worse/HeavyRain'})


# Visualising Daily count of rented bikes

plt.figure(figsize=[12,5])
sns.barplot(bike['Weather'],bike['Count'])
plt.title('Average Count depending on Weather', fontsize = 20)
plt.show()

"""**Observations:**

It shows that if the weather is clear, the demand is more.

If the weather is bad, demand decreases drastically.
"""

# Mapping Holiday varible proper names for better visibilty

bike['holiday'] = bike['holiday'].map({0:'No',1:'Yes'})

# Visualising Holiday wise count of rented bikes

plt.figure(figsize=[7,4])
sns.barplot(bike['holiday'],bike['Count'])
plt.title('Average Count depending on Holidays', fontsize = 20)
plt.show()

"""Decrease of demand if it is a holiday."""

bike.info()

"""Numerical columns visulization(Scatter plot)"""

sns.pairplot(data = bike, x_vars = ['temp','atemp','Humidity','windspeed'] , y_vars = ['Count'])

"""The above graphs shows that linear relation ship exist between temp, atemp and count.

**Auto Exploratory Data Analysis(EDA)**
"""

! pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip

# Pandas profiling
from pandas_profiling import ProfileReport
prof = ProfileReport(bike)
prof.to_file(output_file = 'output.html')

"""#**Data preprocessing**"""

for col in bike:
    print(bike[col].value_counts(ascending=False), '\n\n\n')

"""No unknown values in the data set."""

# checking duplicates
bike.duplicated().sum()

"""No duplicates"""

# Checking missing and null values
bike.isna().sum()  # or
bike.isnull().sum()

"""No null/NaN values."""

## Distibution plots
def draw_plots(data, var, rows, cols):
    fig=plt.figure(figsize=(20,20))
    for i, f in enumerate(var):
        ax=fig.add_subplot(rows,cols,i+1)
        data[f].hist(bins=20,ax=ax, facecolor='midnightblue')
        ax.set_title(f+'Distribution',color='DarkRed')
 
    fig.tight_layout()

plt.show()
draw_plots(bike,bike.columns,5,3)

# Checking outliers
cols = ['temp', 'atemp', 'Humidity', 'windspeed', 'Count']
for i in cols:
    sns.boxplot(bike[i]); plt.show()

!pip install feature-engine

cols1 = ['Humidity', 'windspeed']
# Outlier tretment
from feature_engine.outliers import Winsorizer
winsor = Winsorizer(capping_method ='iqr', # choose IQR rule boundaries or gaussian for mean and std
                   tail = 'both', # cap left, right or both tails
                   fold = 1.5,
                  # variables = ['']
                  )

for i in cols1:
    bike[i] = winsor.fit_transform(bike[[i]])

for i in cols1:
    sns.boxplot(bike[i]); plt.show()

"""Outliers are removed."""

bike = pd.get_dummies(bike, drop_first=True)
bike.info()

bike.head()

"""**Rescaling Numerical features.**"""

# importing MinMax scaler from preprocessing module of sklearn library
from sklearn.preprocessing import MinMaxScaler

# defining a variable scaler for minmax scaling
scaler = MinMaxScaler()

# Min_Max scaling on all the numericals variables and leaving Count variable aside
cols2 = ['temp', 'atemp', 'Humidity', 'windspeed', 'Count']

bike[cols2] = scaler.fit_transform(bike[cols2])
bike[cols2].head()

bike.head()

bike.shape

bike.describe()

"""**Correlation Matrix**"""

# Let's check the correlation coefficients to see which variables are highly correlated.

plt.figure(figsize = (25,20))
sns.heatmap(bike.corr(), annot = True, cmap= 'coolwarm')
plt.show()

bike.columns

bike.rename(columns = {'Weather_Good/Clear':'Weather_Good_Clear', 'Weather_Moderate/Misty':'Weather_Moderate_Misty'}, inplace = True)

import statsmodels.formula.api as smf 
         
ml1 = smf.ols('Count ~ temp + atemp + Humidity + windspeed + Season_spring + Season_summer + Season_winter + Year_2019 + Month_Aug + Month_Dec + Month_Feb + Month_Jan + Month_July + Month_June+ Month_Mar + Month_May + Month_Nov + Month_Oct + Month_Sept + holiday_Yes + weekday_Mon + weekday_Sat + weekday_Sun + weekday_Thurs + weekday_Tues + weekday_Wed + workingday_Yes + Weather_Good_Clear + Weather_Moderate_Misty', data = bike).fit() # regression model

# Summary
ml1.summary()

from statsmodels.stats.outliers_influence import variance_inflation_factor

X = bike[list(bike.select_dtypes(include = ['int64', 'float64', 'uint8']).columns)]

# Profit feature is dependent or out put feature so we are deleting
X = X.drop('Count', axis = 1)

## VIF dataframe
vif_bike = pd.DataFrame()
vif_bike["feature"] = X.columns

## calculating VIF for each feature
vif_bike["VIF"] = [variance_inflation_factor(X.values, i)
                   for i in range(len(X.columns))]
print(vif_bike)

# Drop columns have high VIF>10 and high  p>0.05
bike.drop(["atemp", "Month_Aug", "Month_Mar", "Month_June", "Month_Oct", "weekday_Sat", "workingday_Yes", "weekday_Sun", "weekday_Mon"], axis = 1, inplace = True)

"""**This model seems to be VERY LOW Multicollinearity between the predictors and the p-values for all the predictors seems to be significant. For now, we will consider this as our final model (unless the Test data metrics are not significantly close to this number).**

*  Intercept	 = 0.1832
*  temp       =	0.2544
*  Humidity   = 	-0.1361
*  windspeed	 = -0.1160
*  Season_spring =	-0.0954 
*  Season_summer = 	0.0055
*  Season_winter =	0.0855
*  Year_2019	= 0.2324
*  Month_Dec = 	-0.0650	
*  Month_Feb	= -0.0382	
*  Month_Jan= 	-0.0562	
*  Month_July=	-0.0469	
*  Month_May	= 0.0324
*  Month_Nov= 	-0.0665	
*  Month_Sept	= 0.0629	
*   holiday_Yes           =	-0.1065	
*  weekday_Thurs          =	-0.0177	
*  weekday_Tues         	= -0.0301	
*  weekday_Wed            =	-0.0329	
*  Weather_Good_Clear     =	0.2213	
*  Weather_Moderate_Misty =	0.1694

**F Statistics** :

F-Statistics is used for testing the overall significance of the Model: Higher the F-Statistics, more significant the Model is.

F-statistic: 134.1

Prob (F-statistic): 2.17e-263

**The multi linear regression equation :**

Count =  0.1832 + (temp * 0.2544) - (Humidity * 0.1361) - (windspeed * 0.1160) - (Season_spring * 0.0954) + (Season_summer * 0.0055) +  (Season_winter * 0.0855) + (Year_2019 * 0.2324) - (Month_Dec * 0.0650) - (Month_Feb * 0.0382) - (Month_Jan * 0.0562) - (Month_July * 0.0469) +
(Month_May * 0.0324) - (Month_Nov * 0.0665) + (Month_Sept * 0.0629) -
(holiday_Yes * 0.1065) - (weekday_Thurs * 0.0177) - (weekday_Tues * 0.0301) - (weekday_Wed * 0.0329)+ (Weather_Good_Clear * 0.2213) +
(Weather_Moderate_Misty * 0.1694)

# **Split the data into Train and Test**
"""

# Split the data set into train(70% of the data) and test(30% of the data)
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(bike.drop("Count", axis = 1), bike.Count, test_size = 0.3, random_state = 42)

print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)

"""#**Model Building**"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, make_scorer
rmse =lambda y, y_hat: np.sqrt(mean_squared_error(y, y_hat))

lm = LinearRegression()
lm.fit(x_train, y_train)

y_pred_test = lm.predict(x_test)

result_test = pd.DataFrame({'Actual':y_test, "Predicted": y_pred_test})
result_test.head(10)

## importing r2_score module
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

# predicting the accuracy score
score_test = r2_score(y_test, y_pred_test)

print('R2 score(test): ', score_test)
print('Mean squared error(test): ', mean_squared_error(y_test, y_pred_test))
print('Root Mean squared error(test): ', np.sqrt(mean_squared_error(y_test, y_pred_test)))

y_pred_train = lm.predict(x_train)

result_train = pd.DataFrame({'Actual':y_train, "Predicted": y_pred_train})
result_train.head(10)

# residual calculations
res = y_train - y_pred_train

# Plot the histogram of the error terms

fig = plt.figure(figsize=[7,5])
sns.distplot((res), bins = 20) 
plt.xlabel('Errors', fontsize = 18)
plt.show()

"""Residuals are normally distributed."""

# Check for Homoscedasticity
plt.figure(figsize = [8,5])
p = sns.scatterplot(y_pred_train,res)
plt.xlabel('y_pred/predicted values')
plt.ylabel('Residuals')

p = sns.lineplot([0,1],[0,0],color='red')

"""Residuals have equal or almost equal variance across the regression line."""

score_train = r2_score(y_train, y_pred_train)

print('R2 score(train): ', score_train)
print('Mean squared error(train): ', mean_squared_error(y_train, y_pred_train))
print('Root Mean squared error(train): ', np.sqrt(mean_squared_error(y_train, y_pred_train)))

plt.scatter(y_test, y_pred_test)
plt.ylabel("y_pred_test")
plt.xlabel("y_test")

R2_test =  0.8436298219326539
# n is number of rows in X
n = x_test.shape[0]

# Number of features (predictors, p) is the shape along axis 1
p = x_test.shape[1]

# We find the Adjusted R-squared using the formula
adjusted_R2_test = 1-(1-R2_test)*(n-1)/(n-p-1)
print('adjusted R2 score(test):', adjusted_R2_test)

R2_train =  0.8445364321968072
# n is number of rows in X
n = x_test.shape[0]

# Number of features (predictors, p) is the shape along axis 1
p = x_test.shape[1]

# We find the Adjusted R-squared using the formula
adjusted_R2_train = 1-(1-R2_train)*(n-1)/(n-p-1)
print('adjusted R2 score(train):', adjusted_R2_train)

"""# **Final Reuslt(MLR):**

* R2 score(test):  0.8437

* R2 score(train):  0.8445

* adjusted R2 score(test): 0.8278

* adjusted R2 score(train): 0.8288

Its right fit model.

#**AUTOML:  get the best model used as TPOT optimizer**
"""

!pip install TPOT

from sklearn.metrics import mean_squared_error, make_scorer
rmse =lambda y, y_hat: np.sqrt(mean_squared_error(y, y_hat))
from tpot import TPOTRegressor
rmse_scorer = make_scorer(rmse, greater_is_better = False)
pipeline_optimizer = TPOTRegressor(
    scoring = rmse_scorer,
    max_time_mins = 60,
    random_state = 42,
    verbosity = 2
    )
pipeline_optimizer.fit(x_train, y_train)

print(pipeline_optimizer.score(x_test, y_test))

pipeline_optimizer.fitted_pipeline_
pipeline_optimizer.export('bestmodel.py')

import numpy as np
import pandas as pd
from sklearn.ensemble import ExtraTreesRegressor
from sklearn.linear_model import ElasticNetCV, RidgeCV
from sklearn.model_selection import train_test_split
from sklearn.pipeline import make_pipeline, make_union
from tpot.builtins import StackingEstimator
from xgboost import XGBRegressor
from tpot.export_utils import set_param_recursive

exported_pipeline = make_pipeline(
    StackingEstimator(estimator=RidgeCV()),
    StackingEstimator(estimator=ExtraTreesRegressor(bootstrap=True, max_features=0.4, min_samples_leaf=4, min_samples_split=19, n_estimators=100)),
    StackingEstimator(estimator=XGBRegressor(learning_rate=0.1, max_depth=7, min_child_weight=18, n_estimators=100, n_jobs=1, objective="reg:squarederror", subsample=0.5, verbosity=0)),
    ElasticNetCV(l1_ratio=0.05, tol=0.0001)
)

exported_pipeline.fit(x_train, y_train)

y_pred_test = exported_pipeline.predict(x_test)

result_test = pd.DataFrame({'Actual':y_test, "Predicted": y_pred_test})
result_test.head(10)

## importing r2_score module
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

# predicting the accuracy score
score_test = r2_score(y_test, y_pred_test)

print('R2 score(test): ', score_test)
print('Mean squared error(test): ', mean_squared_error(y_test, y_pred_test))
print('Root Mean squared error(test): ', np.sqrt(mean_squared_error(y_test, y_pred_test)))

y_pred_train = exported_pipeline.predict(x_train)

result_train = pd.DataFrame({'Actual':y_train, "Predicted": y_pred_train})
result_train.head(10)

score_train = r2_score(y_train, y_pred_train)

print('R2 score(train): ', score_train)
print('Mean squared error(train): ', mean_squared_error(y_train, y_pred_train))
print('Root Mean squared error(train): ', np.sqrt(mean_squared_error(y_train, y_pred_train)))

plt.scatter(y_test, y_pred_test)

"""#**Final Reuslt(AUTOML):**

R2 score(test): 0.8974

R2 score(train): 0.9538

Its  a slighly over fit model.

# **Report:**

As per our final Model, the top 3 predictor variables that influences the bike booking are:

Temperature (temp) - A coefficient value of ‘0.2544’ indicated that a unit increase in temp variable increases the bike hire numbers by 0.2544 units.

Year - A coefficient value of ‘0.2324’ indicated that a unit increase in year variable increases the bike hire numbers by 0.2324 units.
So, it's suggested to consider these variables utmost importance while planning, to achive maximum Booking.

Weather Situation (Good_Clear) - A coefficient value of ‘0.2213’ indicated that, w.r.t Weather, a unit increase in Weather variable increases the bike hire numbers by 0.2213 units.
"""